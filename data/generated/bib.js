define({ entries : {
    "AmershiSaleema2019Gfhi": {
        "abstract": "Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for humanAI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of guidelines for human-AI interaction design.",
        "address": "NEW YORK",
        "author": "Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric",
        "booktitle": "CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS",
        "copyright": "Copyright 2019 Elsevier B.V., All rights reserved.",
        "doi": "10.1145/3290605.3300233",
        "isbn": "1450359701",
        "keywords": "type:application,AI-infused systems , Computer Science , Computer Science Cybernetics , Computer Science Information Systems , Computer Science Theory & Methods , Design guidelines , Human-AI interaction , Science & Technology , Technology",
        "language": "eng",
        "organization": "Assoc Comp Machinery",
        "publisher": "Assoc Computing Machinery",
        "title": "Guidelines for human-AI interaction",
        "type": "inproceedings",
        "url": "https://dl.acm.org/doi/10.1145/3290605.3300233",
        "year": "2019"
    },
    "CanasJoseJ2022AaEW": {
        "abstract": "The relationship between a human being and an AI system has to be considered as a collaborative process between two agents during the performance of an activity. When there is a collaboration between two people, a fundamental characteristic of that collaboration is that there is co-supervision, with each agent supervising the actions of the other. Such supervision ensures that the activity achieves its objectives, but it also means that responsibility for the consequences of the activity is shared. If there is no co-supervision, neither collaborator can be held co-responsible for the actions of the other. When the collaboration is between a person and an AI system, co-supervision is also necessary to ensure that the objectives of the activity are achieved, but this also means that there is co-responsibility for the consequences of the activities. Therefore, if each agent's responsibility for the consequences of the activity depends on the effectiveness and efficiency of the supervision that that agent performs over the other agent's actions, it will be necessary to take into account the way in which that supervision is carried out and the factors on which it depends. In the case of the human supervision of the actions of an AI system, there is a wealth of psychological research that can help us to establish cognitive and non-cognitive boundaries and their relationship to the responsibility of humans collaborating with AI systems. There is also psychological research on how an external observer supervises and evaluates human actions. This research can be used to programme AI systems in such a way that the boundaries of responsibility for AI systems can be established. In this article, we will describe some examples of how such research on the task of supervising the actions of another agent can be used to establish lines of shared responsibility between a human being and an AI system. The article will conclude by proposing that we should develop a methodology for assessing responsibility based on the results of the collaboration between a human being and an AI agent during the performance of one common activity.",
        "address": "Switzerland",
        "author": "Ca\u00f1as, Jos\u00e9 J.",
        "copyright": "Copyright 2022 Elsevier B.V., All rights reserved.",
        "doi": "10.3389/fpsyg.2022.836650",
        "issn": "1664-1078",
        "journal": "Frontiers in psychology",
        "keywords": "type:evaluation,other:agent collaboration , ethics , human factors , human-AI interaction , Psychology",
        "language": "eng",
        "pages": "836650--836650",
        "publisher": "Frontiers Media S.A",
        "title": "AI and Ethics When Human Beings Collaborate With AI Agents",
        "type": "article",
        "url": "https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2022.836650/full",
        "volume": "13",
        "year": "2022"
    },
    "HeyderTeresa2023Emoh": {
        "abstract": "\u2022Literature review on the ethical management of human-AI interaction (HAI).\u2022Framework on the ethical management of HAI using sociotechnical system theory.\u2022Theorizing ethical management of HAI through the lens of sociomateriality.\u2022Research agenda for future research on the ethical management of HAI.\u2022Foundations to foster ethics in the strategic management of HAI in organizations. AI-based technologies have changed the nature of the symbiosis between humans and AI, and so strategic management of human-AI interaction in organizations requires deeper ethical considerations. Aligning AI with human values requires a systematic understanding of the ethical management of human-AI interaction. We conduct a theoretical review, from a sociotechnical perspective, and analyze ethical management of human-AI interaction through the lens of sociomateriality. Our systematic approach helps explain and clarify the interdependencies between two ethical perspectives \u2013 duty and virtue ethics \u2013 in sociotechnical systems. We also provide a theoretical framework that leads to seven avenues for future research.",
        "address": "AMSTERDAM",
        "author": "Heyder, Teresa and Passlack, Nina and Posegga, Oliver",
        "copyright": "2023 The Author(s)",
        "doi": "0.1016/j.jsis.2023.101772",
        "issn": "0963-8687",
        "journal": "The journal of strategic information systems",
        "keywords": "type:evaluation,Artificial intelligence , Business & Economics , Computer Science , Computer Science Information Systems , Ethics , Human-AI interaction , Information Science & Library Science , Management , Science & Technology , Social Sciences , Sociomateriality , Technology , Theoretical review",
        "language": "eng",
        "number": "3",
        "pages": "101772",
        "publisher": "Elsevier B.V",
        "title": "Ethical management of human-AI interaction: Theory development review",
        "type": "article",
        "url": "https://doi-org.nottingham.idm.oclc.org/10.1016/j.jsis.2023.101772",
        "volume": "32",
        "year": "2023"
    },
    "LegaspiRoberto2024Tsoa": {
        "abstract": "Sense of agency (SoA) is the perceived control over one\u2019s actions and their consequences, and through this one feels responsible for the consequent outcomes in the world. We analyze the far-reaching implications of a two-pronged knowledge on SoA and its impact on human\u2013AI interactions. We argue that although there are interesting research efforts for an AI to inherently possess SoA, they are still sparse, constrained in scope and present unclear immediate benefit to the design of AI-enabled systems. We also argue that the knowledge on how human SoA is affected by an AI that is perceived to possess a sense of control presents more immediate benefit to AI, in particular, to eliciting positive human attitudes toward AI. Third, and lastly, we argue that research efforts for an AI to adapt to the dynamic changes of human SoA are practically non-existent primarily due to the difficulty of modeling, inferring and adaptively responding to human SoA in complex natural settings. We proceed by first delving deep into the influential and recent theoretical underpinnings of SoA, and discuss its conceptual reach in different disciplines and how it is applied in real-world research. We organize a substantial part of our paper to put forward and elucidate our three argumentative points while supported by evidence in the literature. \u2022Sense of agency (SoA) research has far-reaching implications for human\u2013AI interactions.\u2022Research on innate SoA in AI is constrained, with unclear immediate social benefits.\u2022Perception of SoA in AI can positively influence human SoA and attitude toward AI.\u2022Research on AI that adapts to dynamic human SoA changes is compelling and nascent.",
        "author": "Legaspi, Roberto and Xu, Wenzhen and Konishi, Tatsuya and Wada, Shinya and Kobayashi, Nao and Naruse, Yasushi and Ishikawa, Yuichi",
        "copyright": "2024 The Authors",
        "doi": "10.1016/j.knosys.2023.111298",
        "issn": "0950-7051",
        "journal": "Knowledge-based systems",
        "keywords": "type:application,Human\u2013AI interaction , Machine agency , Sense of agency",
        "language": "eng",
        "pages": "111298",
        "publisher": "Elsevier B.V",
        "title": "The sense of agency in human\u2013AI interactions",
        "type": "article",
        "url": "https://www-sciencedirect-com.nottingham.idm.oclc.org/science/article/pii/S0950705123010468?via%3Dihub",
        "volume": "286",
        "year": "2024"
    },
    "LehmannFlorian2021EAaa": {
        "abstract": "Autocompletion is an approach that extends and continues partial user input. We propose to interpret autocompletion as a basic interaction concept in human-AI interaction. We first describe the concept of autocompletion and dissect its user interface and interaction elements, using the well-established textual autocompletion in search engines as an example. We then highlight how these elements reoccur in other application domains, such as code completion, GUI sketching, and layouting. This comparison and transfer highlights an inherent role of such intelligent systems to extend and complete user input, in particular useful for designing interactions with and for generative AI. We reflect on and discuss our conceptual analysis of autocompletion to provide inspiration and a conceptual lens on current challenges in designing for human-AI interaction.",
        "author": "Lehmann, Florian and Buschek, Daniel",
        "copyright": "Copyright 2021 Elsevier B.V., All rights reserved.",
        "doi": "https://doi.org/10.1515/icom-2020-0025",
        "issn": "1618-162X",
        "journal": "I-com",
        "keywords": "type:technique,autocompletion  ,human-AI interaction ,interaction patterns , user-centred AI",
        "language": "eng",
        "number": "3",
        "pages": "251--264",
        "publisher": "De Gruyter Oldenbourg",
        "title": "Examining Autocompletion as a Basic Concept for Interaction with Generative AI",
        "type": "article",
        "volume": "19",
        "year": "2021"
    },
    "LiJiwei2016ASFD": {
        "abstract": "In this paper, we propose a simple, fast decoding algorithm that fosters diversity in neural generation. The algorithm modifies the standard beam search algorithm by adding an inter-sibling ranking penalty, favoring choosing hypotheses from diverse parents. We evaluate the proposed model on the tasks of dialogue response generation, abstractive summarization and machine translation. We find that diverse decoding helps across all tasks, especially those for which reranking is needed. We further propose a variation that is capable of automatically adjusting its diversity decoding rates for different inputs using reinforcement learning (RL). We observe a further performance boost from this RL technique. This paper includes material from the unpublished script \"Mutual Information and Diverse Decoding Improve Neural Machine Translation\" (Li and Jurafsky, 2016).",
        "address": "Ithaca",
        "author": "Li, Jiwei and Monroe, Will and Jurafsky, Dan",
        "copyright": "2016. This work is published under http://arxiv.org/licenses/nonexclusive-distrib/1.0/ (the \u201cLicense\u201d). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.",
        "doi": "10.48550/arxiv.1611.08562",
        "issn": "2331-8422",
        "journal": "arXiv.org",
        "keywords": "type:technique,Algorithms , Codes , Decoding , Machine translation , Parents , Search algorithms",
        "language": "eng",
        "publisher": "Cornell University Library, arXiv.org",
        "title": "A Simple, Fast Diverse Decoding Algorithm for Neural Generation",
        "type": "article",
        "url": "https://www.proquest.com/docview/2080874050?pq-origsite",
        "year": "2016"
    },
    "Rong20242104": {
        "abstract": "Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how human-computer interaction (HCI) and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97 core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.  \u00a9 1979-2012 IEEE.",
        "author": "Rong, Yao and Leemann, Tobias and Nguyen, Thai-Trang and Fiedler, Lisa and Qian, Peizhu and Unhelkar, Vaibhav and Seidel, Tina and Kasneci, Gjergji and Kasneci, Enkelejda",
        "author_keywords": "Explainable AI (XAI); explainable ML; human-AI interaction; human-centered XAI; user study",
        "doi": "10.1109/TPAMI.2023.3331846",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "keywords": "type:evaluation,Algorithms, Humans, Artificial intelligence, Cognitive systems, Job analysis, Explainable ML, Human -AI interaction, Human -centered XAI, Human-centered evaluation, Systematic, Systematic literature review, Task analysis, Usability, User study, XAI, algorithm, human, Human computer interaction",
        "note": "Cited by: 3; All Open Access, Bronze Open Access",
        "number": "4",
        "pages": "2104 \u2013 2122",
        "publication_stage": "Final",
        "source": "Scopus",
        "title": "Towards Human-Centered Explainable AI: A Survey of User Studies for Model Explanations",
        "type": "ARTICLE",
        "url": "https://www.scopus.com/inward/record.uri?eid",
        "volume": "46",
        "year": "2024"
    },
    "SreedharanSarath2023HAAf": {
        "abstract": "We are living through a revolutionary moment in AI history. Users from diverse walks of life are adopting and using AI systems for their everyday use cases at a pace that has never been seen before. However, with this proliferation, there is also a growing recognition that many of the central open problems within AI are connected to how the user interacts with these systems. To name two prominent examples, consider the problems of explainability and value alignment. Each problem has received considerable attention within the wider AI community, and much promising progress has been made in addressing each of these individual problems. However, each of these problems tends to be studied in isolation, using very different theoretical frameworks, while a closer look at each easily reveals striking similarities between the two problems. In this article, I wish to discuss the framework of human\u2010aware AI (HAAI) that aims to provide a unified formal framework to understand and evaluate human\u2013AI interaction. We will see how this framework can be used to both understand explainability and value alignment and how the framework also lays out potential novel avenues to address these\u00a0problems.",
        "author": "Sreedharan, Sarath",
        "copyright": "2023 The Authors. published by John Wiley & Sons Ltd on behalf of Association for the Advancement of Artificial Intelligence.",
        "doi": "10.1002/aaai.12142",
        "issn": "0738-4602",
        "journal": "The AI magazine",
        "keywords": "type:technique,Computer Science ,Computer Science,Artificial Intelligence ,Science & Technology ,Technology",
        "language": "eng",
        "number": "4",
        "pages": "460--466",
        "title": "Human\u2010aware AI \u2014A foundational framework for human\u2013AI interaction",
        "type": "article",
        "url": "https://onlinelibrary.wiley.com/doi/epdf/10.1002/aaai.12142",
        "volume": "44",
        "year": "2023"
    },
    "SubeeThomas2023Hiir": {
        "abstract": "Artificial intelligence (AI) is increasingly discussed as an innovation enabler for the enhancement of circular economy (CE) approaches in industries. The further deployment of intelligent technologies is considered to be very promising particularly in remanufacturing, which can be regarded as an implementation approach of CE at a firm level. AI's potential to contribute to advancements in remanufacturing can be traced back to these modern technologies' extended capacities of supporting and assisting humans during rather manual processes which are regarded as more common in remanufacturing than in traditional linear production. As a result, we argue that in future application scenarios, humans are going to interact more often with AI agents who may direct and assist humans' behaviour and decision-making processes. We assume that a better understanding of the specific dynamics and novel aspects of these kind of newly emerging human-AI systems is a key prerequisite for sustainable process innovation, particularly in remanufacturing organisations. However, empirical-based contributions about humans' behavioural changes in interaction with AI agents have so far been rather rare and limited, especially in the field of remanufacturing and CE. In this article, we seek to contribute to this gap in research by exploring the interaction between shop floor workers and an AI agent based on a case study research approach at a plant of a German automotive supplier that is remanufacturing used parts. We conducted semi-structured interviews among the shop floor workers who are involved in a joint decision-making task with an AI agent. We interpret the findings of our qualitative data in the light of related research in the field of AI in CE, AI implementation in organisation and human-AI interaction literature. In summary, our analysis reveals 13 behavioural patterns that shop floor workers reported on referring to their interaction with the AI agent. The behavioural patterns are systemised into a cognitive, emotional and social dimension of a competence framework. These findings shall contribute to a more specific understanding about how humans interact with AI agents at work, while considering the specific context variables of the interaction paradigm and the AI agent's role during joint decision-making in a human-AI system. Implications for literature in the field of human-AI interaction as well as AI implementation in organisations with a particular focus on CE are discussed.",
        "address": "ABINGDON",
        "author": "S\u00fc\u00dfe, Thomas and Kobert, Maria and Kries, Caroline",
        "copyright": "2023 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group. 2023",
        "doi": "10.1080/10301763.2023.2251103",
        "issn": "1030-1763",
        "journal": "Labour & industry (Brisbane, Qld.)",
        "keywords": "type:application,AI competence , AI-based agents , Business & Economics , Human-AI interaction , Industrial Relations & Labor , Social Sciences , transformation of work",
        "language": "eng",
        "number": "3",
        "pages": "344--363",
        "publisher": "Routledge",
        "title": "Human-AI interaction in remanufacturing: exploring shop floor workers' behavioural patterns within a specific human-AI system",
        "type": "article",
        "url": "https://doi-org.nottingham.idm.oclc.org/10.1080/10301763.2023.2251103",
        "volume": "33",
        "year": "2023"
    },
    "VinyalsOriol2015ANCM": {
        "abstract": "Conversational modeling is an important task in natural language understanding and machine intelligence. Although previous approaches exist, they are often restricted to specific domains (e.g., booking an airline ticket) and require hand-crafted rules. In this paper, we present a simple approach for this task which uses the recently proposed sequence to sequence framework. Our model converses by predicting the next sentence given the previous sentence or sentences in a conversation. The strength of our model is that it can be trained end-to-end and thus requires much fewer hand-crafted rules. We find that this straightforward model can generate simple conversations given a large conversational training dataset. Our preliminary results suggest that, despite optimizing the wrong objective function, the model is able to converse well. It is able extract knowledge from both a domain specific dataset, and from a large, noisy, and general domain dataset of movie subtitles. On a domain-specific IT helpdesk dataset, the model can find a solution to a technical problem via conversations. On a noisy open-domain movie transcript dataset, the model can perform simple forms of common sense reasoning. As expected, we also find that the lack of consistency is a common failure mode of our model.",
        "address": "Ithaca",
        "author": "Vinyals, Oriol and Le, Quoc",
        "copyright": "2015. This work is published under http://arxiv.org/licenses/nonexclusive-distrib/1.0/ (the \u201cLicense\u201d). Notwithstanding the ProQuest Terms and Conditions, you may use this content in accordance with the terms of the License.",
        "doi": "10.48550/arxiv.1506.05869",
        "issn": "2331-8422",
        "journal": "arXiv.org",
        "keywords": "type:technique,Datasets , Failure modes , Sentences",
        "language": "eng",
        "publisher": "Cornell University Library, arXiv.org",
        "title": "A Neural Conversational Model",
        "type": "article",
        "url": "https://www.proquest.com/docview/2083270488?pq-origsite",
        "year": "2015"
    }
}});